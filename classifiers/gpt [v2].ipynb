{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install\n",
    "# %pip install openai dill seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# # Corpus\n",
    "# CORPUS = \"synthetic_data_corpus\"\n",
    "# # MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "# # MODEL = \"gpt-4-1106-preview\"\n",
    "# MODEL = \"df@meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "\n",
    "# # The name of the experiment (i.e. where to save the results)\n",
    "# # EXPERIMENT_NAME = \"climate_change_synthetic_k1_with_fewshot_and_both_and_neither\"\n",
    "# from datetime import datetime\n",
    "# EXPERIMENT_NAME = f\"{CORPUS}_{MODEL}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\".replace(\"/\", \"_\")\n",
    "\n",
    "# Corpus\n",
    "# CORPUS = \"synthetic_data_corpus\"\n",
    "# CORPUS = \"converted_climate_change_gpt-4-turbo-preview_gpt-4-turbo-preview_10_10\"\n",
    "# CORPUS = \"/workspaces/dev/projects/narratives/synthetic/corpora/climate_change/20_10.json\"\n",
    "CORPUS_NAME = \"climate_change\"\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"gpt-3.5-turbo-0125\"\n",
    "# MODEL = \"gpt-4-turbo-preview\"\n",
    "MODEL = \"df@meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "# MODE = \"seeds\"\n",
    "# MODE = \"distilled\"\n",
    "MODE = \"summaries\"\n",
    "# MODE = \"zero-shot\"\n",
    "\n",
    "# The name of the experiment (i.e. where to save the results)\n",
    "# EXPERIMENT_NAME = \"climate_synthetic_test_k2\"\n",
    "# EXPERIMENT_NAME = CORPUS_NAME + \"_\" + MODEL + \"_gpt\"\n",
    "EXPERIMENT_NAME = \"test_ignore_me\"\n",
    "\n",
    "CORPUS_SIZE = \"/2_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = (\n",
    "    \"/workspaces/dev/projects/narratives/synthetic/corpora/\"\n",
    "    + CORPUS_NAME\n",
    "    # + \"/20_10.json\"\n",
    "    # + \"/\"\n",
    "    + CORPUS_SIZE\n",
    "    + \".json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2863.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletion(id='chatcmpl-8b753fc646c94cff8425a1a1df862267', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='  cat', role='assistant', function_call=None, tool_calls=None, name=None))], created=1708565309, model='meta-llama/Llama-2-70b-chat-hf', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3, prompt_tokens=105, total_tokens=108)), ChatCompletion(id='chatcmpl-44184bbfb9f44b609b618552dc61287d', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='  dog', role='assistant', function_call=None, tool_calls=None, name=None))], created=1708565309, model='meta-llama/Llama-2-70b-chat-hf', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3, prompt_tokens=105, total_tokens=108)), ChatCompletion(id='chatcmpl-7238cc1cc15e4fc9803d31abe9fa271c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='  cat', role='assistant', function_call=None, tool_calls=None, name=None))], created=1708565310, model='meta-llama/Llama-2-70b-chat-hf', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3, prompt_tokens=111, total_tokens=114)), ChatCompletion(id='chatcmpl-5b8c6eddb35b451597360062018f34a2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='  dog', role='assistant', function_call=None, tool_calls=None, name=None))], created=1708565310, model='meta-llama/Llama-2-70b-chat-hf', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=3, prompt_tokens=113, total_tokens=116))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1135951/866871140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m }\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m classifications, usages = get_classifications(\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m )\n",
      "\u001b[0;32m/tmp/ipykernel_1135951/866871140.py\u001b[0m in \u001b[0;36mget_classifications\u001b[0;34m(texts, classes, model, batch_size, num_threads, max_tokens)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#     )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     return get_classifications_gpt4(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;32m/tmp/ipykernel_1135951/866871140.py\u001b[0m in \u001b[0;36mget_classifications_gpt4\u001b[0;34m(texts, classes, model, batch_size, num_threads, max_tokens)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Get the token logprobs for each completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0musages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1135951/866871140.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Get the token logprobs for each completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0musages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "from soda.openai.text import completion_model_batched, instruct_chat_model_batched\n",
    "\n",
    "\n",
    "def get_classifications(\n",
    "    texts, classes, model, batch_size=1, num_threads=1, max_tokens=1\n",
    "):\n",
    "    # if \"gpt-4\" in model or model == \"gpt-3.5-turbo\" or model == \"gpt-3.5-turbo-0125\":\n",
    "    #     return get_classifications_gpt4(\n",
    "    #         texts, classes, model, batch_size, num_threads, max_tokens\n",
    "    #     )\n",
    "    # else:\n",
    "    #     return get_classifications_instruct(\n",
    "    #         texts, classes, model, batch_size, num_threads, max_tokens\n",
    "    #     )\n",
    "\n",
    "    return get_classifications_gpt4(\n",
    "        texts, classes, model, batch_size, num_threads, max_tokens\n",
    "    )\n",
    "\n",
    "\n",
    "def get_classifications_gpt4(\n",
    "    texts, classes, model, batch_size=1, num_threads=1, max_tokens=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the classification probabilities using the GPT-4 chat API\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the system message\n",
    "    system_message = \"\"\"\n",
    "You are a classification system. You will be given some text and you must respond with a single class that the text most likely belongs to. Ensure your response is only the class, with no other text. These are the classes you can choose from:\n",
    "\"\"\".strip()\n",
    "    system_message += \"\\n\\n\"\n",
    "    for class_ in classes:\n",
    "        system_message += f\"*** Class '{class_}' ***\\n\"\n",
    "        system_message += classes[class_]\n",
    "        system_message += \"\\n\"\n",
    "\n",
    "    # Map the texts to the prompts\n",
    "    # prompts = [\n",
    "    #     # \"Text: \" + text + \"\\nClass (from { \" + \", \".join(classes.keys()) + \" }):\"\n",
    "    #     # \"This is the text: \"\n",
    "    #     + text\n",
    "    #     # + \"\\n\\n\"\n",
    "    #     # + \"Respond with the class that best fits the text, from these classes:\n",
    "    #     # + \", \".join(classes.keys())\n",
    "    #     for text in texts\n",
    "    # ]\n",
    "    prompts = texts\n",
    "\n",
    "    # # Print a summary of the prompts\n",
    "    # for prompt in prompts:\n",
    "    #     print(\"--- System Message ---\")\n",
    "    #     print(system_message)\n",
    "    #     print()\n",
    "\n",
    "    #     print(\"--- Prompt ---\")\n",
    "    #     print(prompt)\n",
    "    #     print()\n",
    "    #     print()\n",
    "\n",
    "    # Get the completions\n",
    "    results = instruct_chat_model_batched(\n",
    "        system_message,\n",
    "        # texts,\n",
    "        prompts,\n",
    "        model,\n",
    "        num_threads=num_threads,\n",
    "        logprobs=True,\n",
    "        top_logprobs=min(5, len(classes)),\n",
    "        temperature=0.0,\n",
    "        timeout=5,\n",
    "    )\n",
    "\n",
    "    # Get the token logprobs for each completion\n",
    "    responses = [result.choices[0].logprobs.content[0] for result in results]\n",
    "    usages = [result.usage for result in results]\n",
    "\n",
    "    # For each class, get the logprobs for each token\n",
    "    # Use -inf for classes without an entry in the top logprobs\n",
    "    logprobs = []\n",
    "    for response in responses:\n",
    "        classification = {class_: -float(\"inf\") for class_ in classes}\n",
    "\n",
    "        # Get the logprobs for each token\n",
    "        # for token, logprob in response.items():\n",
    "        for top_logprob in response.top_logprobs:\n",
    "            # Get the class for this token\n",
    "            class_ = top_logprob.token.strip()\n",
    "\n",
    "            # Update the classification\n",
    "            classification[class_] = top_logprob.logprob\n",
    "\n",
    "        logprobs.append(classification)\n",
    "\n",
    "    return logprobs, usages\n",
    "\n",
    "\n",
    "# def get_classifications_instruct(\n",
    "#     texts, classes, model, batch_size=1, num_threads=1, max_tokens=1\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Get the classification probabilities for each text and class.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Construct the prompt\n",
    "#     prompt = \"\"\n",
    "#     prompt += \"You are a classification system. Given the text below, you will classify it into either of the given classes. Output the class name.\\n\"\n",
    "#     # prompt += \"You are a classification system. Given the text below, you will classify it into one of the following classes. If no class is suitable, choose \\\"none\\\". If more than one class is suitable, choose \\\"all\\\". Ensure you match the classes exactly, including wording and casing.\\n\"\n",
    "#     # for class_ in classes:\n",
    "#     #     prompt += f\"- {class_}\\n\"\n",
    "#     # for class_, description in classes.items():\n",
    "#     #     prompt += f\"- {class_}: {description}\\n\"\n",
    "#     # prompt += \"*** Class 'a' ***\\n\"\n",
    "#     # prompt += classes[\"a\"]\n",
    "#     # prompt += \"\\n\"\n",
    "\n",
    "#     # prompt += \"*** Class 'b' ***\\n\"\n",
    "#     # prompt += classes[\"b\"]\n",
    "#     # prompt += \"\\n\"\n",
    "\n",
    "#     for class_ in classes:\n",
    "#         prompt += f\"*** Class '{class_}' ***\\n\"\n",
    "#         prompt += classes[class_]\n",
    "#         prompt += \"\\n\"\n",
    "\n",
    "#     prompt += \"\\nText: {TEXT}\\nClass (from { \" + \", \".join(classes.keys()) + \" }):\"\n",
    "\n",
    "#     # Create the prompts for each text\n",
    "#     prompts = [prompt.format(TEXT=text) for text in texts]\n",
    "\n",
    "#     # Get the completions\n",
    "#     completions = completion_model_batched(\n",
    "#         prompts,\n",
    "#         model,\n",
    "#         batch_size=batch_size,\n",
    "#         num_threads=num_threads,\n",
    "#         max_tokens=max_tokens,\n",
    "#         logprobs=2,\n",
    "#     )\n",
    "#     # print(completions)\n",
    "\n",
    "#     usages = [completion.usage for completion in completions]\n",
    "\n",
    "#     # Get the token logprobs for each completion\n",
    "#     logprobs = []\n",
    "#     # For each class, get the logprobs for each token\n",
    "#     # Use -inf for classes without an entry in the top logprobs\n",
    "#     for completion in completions.choices:\n",
    "#         classification = {class_: -float(\"inf\") for class_ in classes}\n",
    "\n",
    "#         # Get the logprobs for each token\n",
    "#         for token, logprob in completion.logprobs.top_logprobs[0].items():\n",
    "#             # Get the class for this token\n",
    "#             class_ = token.strip().replace(\"▁\", \"\")\n",
    "\n",
    "#             # Update the classification\n",
    "#             # classification[class_] = logprob\n",
    "\n",
    "#             # There might be duplicates due to the ▁ character that DF seems to use\n",
    "#             classification[class_] = max(\n",
    "#                 classification.get(class_, -float(\"inf\")), logprob\n",
    "#             )\n",
    "\n",
    "#         logprobs.append(classification)\n",
    "\n",
    "#     return logprobs, usages\n",
    "\n",
    "\n",
    "# Classify a simple dataset about cats and dogs\n",
    "# texts = [\"This is a cat\", \"This is a dog\", \"This is a cat, and this is a dog\"]\n",
    "texts = [\n",
    "    \"This is a cat\",\n",
    "    \"This is a dog\",\n",
    "    \"This is a cat, and this is a dog\",\n",
    "    \"We're not talking about cats and dogs here!\",\n",
    "]\n",
    "# classes = [\"cat\", \"dog\"]\n",
    "classes = {\n",
    "    \"cat\": \"Discusses a cat\",\n",
    "    \"dog\": \"Discusses a dog\",\n",
    "}\n",
    "\n",
    "classifications, usages = get_classifications(\n",
    "    texts, classes, MODEL, batch_size=1, num_threads=2, max_tokens=1\n",
    ")\n",
    "\n",
    "print(classifications)\n",
    "prompt_tokens = sum(usage.prompt_tokens for usage in usages)\n",
    "completion_tokens = sum(usage.completion_tokens for usage in usages)\n",
    "print(\"Prompt tokens:\", prompt_tokens)\n",
    "print(\"Completion token:\", completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing with joblib\n",
    "import os\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "# # Load texts from corpora/{CORPUS}.json\n",
    "# with open(os.path.join(\"../corpora\", f\"{CORPUS}.json\"), \"r\") as f:\n",
    "#     corpus_data = yaml.safe_load(f)\n",
    "\n",
    "with open(CORPUS, \"r\") as f:\n",
    "    corpus_data = yaml.safe_load(f)\n",
    "\n",
    "seeds = corpus_data[\"seeds\"]\n",
    "distilled = corpus_data[\"distilled\"]\n",
    "summarized = corpus_data[\"summarized\"]\n",
    "names = corpus_data[\"names\"]\n",
    "dataset = corpus_data[\"dataset\"]\n",
    "\n",
    "# Convert the dataset to corpus data format\n",
    "corpus_data = []\n",
    "for seed_set in dataset:\n",
    "    for a in seed_set[\"a_first\"][\"a\"]:\n",
    "        corpus_data.append({\"text\": a, \"speakername\": \"a\"})\n",
    "    for b in seed_set[\"a_first\"][\"b\"]:\n",
    "        corpus_data.append({\"text\": b, \"speakername\": \"b\"})\n",
    "    for a in seed_set[\"b_first\"][\"a\"]:\n",
    "        corpus_data.append({\"text\": a, \"speakername\": \"a\"})\n",
    "    for b in seed_set[\"b_first\"][\"b\"]:\n",
    "        corpus_data.append({\"text\": b, \"speakername\": \"b\"})\n",
    "\n",
    "# Shuffle\n",
    "random.shuffle(corpus_data)\n",
    "\n",
    "print(\"Loaded {} texts from corpus\".format(len(corpus_data)))\n",
    "print(\"Total word count:\", sum([len(text[\"text\"].split()) for text in corpus_data]))\n",
    "\n",
    "# Create the training data\n",
    "X = [text[\"text\"] for text in corpus_data]\n",
    "y = [text[\"speakername\"] for text in corpus_data]\n",
    "print(len(X), len(y))\n",
    "\n",
    "# classes = {\n",
    "#     \"a\": \"A helpful statement.\",\n",
    "#     \"b\": \"An unhelpful statement.\",\n",
    "# }\n",
    "\n",
    "# Construct the classes depending on the mode\n",
    "a_desc = \"\"\n",
    "b_desc = \"\"\n",
    "if MODE == \"seeds\":\n",
    "    a_desc = \"\\n\"\n",
    "    b_desc = \"\\n\"\n",
    "    for seed in seeds:\n",
    "        a_desc += \"  \" + seed[\"a\"] + \"\\n\"\n",
    "        b_desc += \"  \" + seed[\"b\"] + \"\\n\"\n",
    "elif MODE == \"distilled\":\n",
    "    a_desc = \"\\n\"\n",
    "    b_desc = \"\\n\"\n",
    "    for seed in distilled:\n",
    "        a_desc += \"  \" + seed[\"a\"] + \"\\n\"\n",
    "        b_desc += \"  \" + seed[\"b\"] + \"\\n\"\n",
    "elif MODE == \"summaries\":\n",
    "    a_desc = summarized[\"a\"]\n",
    "    b_desc = summarized[\"b\"]\n",
    "elif MODE == \"zero-shot\":\n",
    "    a_desc = \"A helpful statement.\"\n",
    "    b_desc = \"An unhelpful statement.\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown mode: {MODE}\")\n",
    "\n",
    "# Define the classes\n",
    "# classes = {\n",
    "#     \"a\": a_desc,\n",
    "#     \"b\": b_desc,\n",
    "# }\n",
    "classes = {\n",
    "    names[\"a\"]: a_desc,\n",
    "    names[\"b\"]: b_desc,\n",
    "}\n",
    "\n",
    "# Get the classifications\n",
    "classifications, usages = get_classifications(\n",
    "    # X, classes, MODEL, batch_size=20, num_threads=50, max_tokens=1\n",
    "    X,\n",
    "    classes,\n",
    "    MODEL,\n",
    "    batch_size=1,\n",
    "    # num_threads=50,\n",
    "    num_threads=20,\n",
    "    max_tokens=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the usage\n",
    "prompt_tokens = sum(usage.prompt_tokens for usage in usages)\n",
    "completion_tokens = sum(usage.completion_tokens for usage in usages)\n",
    "print(\"Prompt tokens:\", prompt_tokens)\n",
    "print(\"Completion token:\", completion_tokens)\n",
    "\n",
    "# Estimate cost given the model\n",
    "c_prompt = -1\n",
    "c_completion = -1\n",
    "if \"gpt-4\" in MODEL:\n",
    "    c_prompt = 0.01 / 1000\n",
    "    c_completion = 0.03 / 1000\n",
    "elif \"gpt-3.5-turbo\" in MODEL:\n",
    "    c_prompt = 0.0005 / 1000\n",
    "    c_completion = 0.0015 / 1000\n",
    "\n",
    "# Estimate cost\n",
    "cost = c_prompt * prompt_tokens + c_completion * completion_tokens\n",
    "if cost >= 0:\n",
    "    print(\"Cost estimate: ${:.3f}\".format(cost))\n",
    "else:\n",
    "    print(\"No cost estimate available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in CSV format\n",
    "data = []\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# Generic\n",
    "incorrect_map = {class_: 0 for class_ in classes}\n",
    "correct_map = {class_: 0 for class_ in classes}\n",
    "\n",
    "a_name = names[\"a\"]\n",
    "b_name = names[\"b\"]\n",
    "\n",
    "for text, truth, classification in tqdm(zip(X, y, classifications), total=len(X)):\n",
    "    # print(text[:20] + \"...\", truth, classification)\n",
    "    # print(\"*** Datum ***\")\n",
    "    # print(\"  Text: \" + text)\n",
    "    # print(\"  Ground Truth: \" + truth)\n",
    "    # print(\"  Classification: \" + str(classification))\n",
    "     \n",
    "    # # Add the data\n",
    "    # data.append(\n",
    "    #     {\n",
    "    #         \"text\": text,\n",
    "    #         # \"myth\": classification[\"myth\"],\n",
    "    #         \"myth\": min(\n",
    "    #             classification.get(\"myth\", -float(\"inf\")),\n",
    "    #             classification.get(\"my\", -float(\"inf\")),\n",
    "    #         ),\n",
    "    #         \"science\": classification[\"science\"],\n",
    "    #         \"classification\": max(classification, key=classification.get),\n",
    "    #         \"truth\": truth,\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    # Map truth to the name\n",
    "    if truth == \"a\":\n",
    "        truth = a_name\n",
    "    elif truth == \"b\":\n",
    "        truth = b_name\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown truth: {truth}\")\n",
    "\n",
    "    # print(\"  Ground Truth (Name): \" + truth)\n",
    "    \n",
    "    # Add the data (class-agnostic)\n",
    "    datum = {\n",
    "        \"text\": text,\n",
    "        \"truth\": truth,\n",
    "        \"classification\": max(classification, key=classification.get),\n",
    "    }\n",
    "    # datum.update(classification)\n",
    "    data.append(datum)\n",
    "\n",
    "    # # if max(classification, key=classification.get) == truth:\n",
    "    # if data[-1][\"classification\"] == truth:\n",
    "    #     correct += 1\n",
    "    #     correct_map[truth] += 1\n",
    "    # else:\n",
    "    #     incorrect_map[truth] += 1\n",
    "\n",
    "    # The classification will be a prefix of one of the classes\n",
    "    # Find the class with that prefix (throw an error if there's more than one match)\n",
    "    # maximum = max(classification, key=classification.get)\n",
    "\n",
    "    # Find the match\n",
    "    # match = None\n",
    "    # for class_ in classes:\n",
    "    #     if class_.startswith(classification):\n",
    "    #         if match is not None:\n",
    "    #             raise ValueError(f\"Multiple matches for {classification}\")\n",
    "    #         match = class_\n",
    "\n",
    "    matches = {}\n",
    "    for class_ in classes:\n",
    "        matches[class_] = float(\"-inf\")\n",
    "        for token in classification:\n",
    "            # print(\"Comparing\", class_, \"with\", token)\n",
    "            # print(f\"Comparing '{class_}' with '{token}'\")\n",
    "            if class_.startswith(token):\n",
    "                # print(\"  Found match!\")\n",
    "                matches[class_] = max(matches[class_], classification[token])\n",
    "\n",
    "    # print(f\"  Truth: {truth}, Prediction: {max(matches, key=lambda k: matches[k])}\")\n",
    "    # print(f\"  Matches:\")\n",
    "    # for class_ in matches:\n",
    "    #     print(f\"    {class_}: {matches[class_]}\")\n",
    "\n",
    "    # Get the best match\n",
    "    # print(\"Matches:\", matches)\n",
    "    match = max(matches, key=lambda k: matches[k])\n",
    "\n",
    "    # Update the datum\n",
    "    data[-1][\"classification\"] = match\n",
    "\n",
    "    # Update the counts\n",
    "    if match == truth:\n",
    "        correct += 1\n",
    "        correct_map[truth] += 1\n",
    "    else:\n",
    "        incorrect_map[truth] += 1\n",
    "\n",
    "    # Assign the match to the classification\n",
    "    total += 1\n",
    "\n",
    "# Show confidence matrix\n",
    "print(\"Correct:\", correct_map)\n",
    "print(\"Incorrect:\", incorrect_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory\n",
    "import os\n",
    "directory = os.path.join(\"corpus_results\", \"gpt\", MODEL, CORPUS_NAME, MODE + \"/\")\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(\"corpus_results\", f\"{EXPERIMENT_NAME}.csv\"), index=False)\n",
    "\n",
    "# Show accuracy and incorrect counts\n",
    "print(\"Accuracy:\", correct / total)\n",
    "print(\"Incorrect counts:\", incorrect_map)\n",
    "\n",
    "# Show a confusion matrix as a pandas df\n",
    "import pandas as pd\n",
    "\n",
    "# Get the confusion matrix\n",
    "confusion_matrix = pd.crosstab(\n",
    "    df[\"truth\"], df[\"classification\"], rownames=[\"Truth\"], colnames=[\"Classification\"]\n",
    ")\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Convert to percentages\n",
    "confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=0)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Save confusion matrix and data to corpus_results/classifiers/{EXPERIMENT_NAME}\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "# Save the confusion matrix\n",
    "confusion_matrix.to_csv(os.path.join(directory, \"confusion_matrix.csv\"))\n",
    "\n",
    "# Save the data\n",
    "df.to_csv(os.path.join(directory, \"data.csv\"), index=False)\n",
    "\n",
    "# Save the usage data as a CSV\n",
    "usage_data = []\n",
    "for usage in usages:\n",
    "    usage_data.append(\n",
    "        {\n",
    "            \"prompt_tokens\": usage.prompt_tokens,\n",
    "            \"completion_tokens\": usage.completion_tokens,\n",
    "        }\n",
    "    )\n",
    "\n",
    "usage_df = pd.DataFrame(usage_data)\n",
    "usage_df.to_csv(os.path.join(directory, \"usage.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
