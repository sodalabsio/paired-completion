{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install\n",
    "# %pip install openai dill seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# # Corpus\n",
    "# CORPUS = \"synthetic_data_corpus\"\n",
    "# # MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "# # MODEL = \"gpt-4-1106-preview\"\n",
    "# MODEL = \"df@meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "\n",
    "# # The name of the experiment (i.e. where to save the results)\n",
    "# # EXPERIMENT_NAME = \"climate_change_synthetic_k1_with_fewshot_and_both_and_neither\"\n",
    "# from datetime import datetime\n",
    "# EXPERIMENT_NAME = f\"{CORPUS}_{MODEL}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\".replace(\"/\", \"_\")\n",
    "\n",
    "# Corpus\n",
    "# CORPUS = \"synthetic_data_corpus\"\n",
    "# CORPUS = \"converted_climate_change_gpt-4-turbo-preview_gpt-4-turbo-preview_10_10\"\n",
    "# CORPUS = \"/workspaces/dev/projects/narratives/synthetic/corpora/climate_change/20_10.json\"\n",
    "CORPUS_NAME = \"voice\"\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "MODEL = \"together@meta-llama/Llama-3-8b-chat-hf\"\n",
    "# MODEL = \"gpt-4-turbo-preview\"\n",
    "\n",
    "# MODE = \"seeds\"\n",
    "MODE = \"distilled\"\n",
    "# MODE = \"summaries\"\n",
    "# MODE = \"zero-shot\"\n",
    "\n",
    "# The name of the experiment (i.e. where to save the results)\n",
    "# EXPERIMENT_NAME = \"climate_synthetic_test_k2\"\n",
    "# EXPERIMENT_NAME = CORPUS_NAME + \"_\" + MODEL + \"_gpt\"\n",
    "EXPERIMENT_NAME = \"voice_experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORPUS_NAME == \"voice\":\n",
    "    CORPUS = \"voice\"\n",
    "    # CORPUS = \"/workspaces/dev/projects/narratives/classifiers/real_world_corpora/the_voice_the_voice_broad_keyscheck_4sep2023_filtered_chars150to1200_gpt-3.5-turbo-instruct_2_2 (1).json\"\n",
    "elif CORPUS_NAME == \"climate\":\n",
    "    CORPUS = \"climate\"\n",
    "    # CORPUS = \"/workspaces/dev/projects/narratives/classifiers/real_world_corpora/with_jensen_garrett_abbott_climate_climate_change_pms_curie_2_-1.json\"\n",
    "else:\n",
    "    CORPUS = (\n",
    "        \"/workspaces/dev/projects/narratives/synthetic/corpora/\"\n",
    "        + CORPUS_NAME\n",
    "        + \"/20_10.json\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from soda.openai.text import completion_model_batched\n",
    "\n",
    "# MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "# texts = [\"This is a test\", \"This is another test! And I\"]\n",
    "\n",
    "# completions = completion_model_batched(\n",
    "#     texts,\n",
    "#     MODEL,\n",
    "#     batch_size=2,\n",
    "#     num_threads=1,\n",
    "#     max_tokens=1,\n",
    "#     # echo=True,\n",
    "#     logprobs=2,\n",
    "# )\n",
    "\n",
    "# print(completions)\n",
    "\n",
    "# # Get the token logprobs for each completion\n",
    "# # logprobs = [completion.logprobs.token_logprobs[0] for completion in completions.choices]\n",
    "# logprobs = []\n",
    "# for completion in completions.choices:\n",
    "#     logprobs.append(completion.logprobs.top_logprobs[0])\n",
    "\n",
    "# for text, logprob in zip(texts, logprobs):\n",
    "#     # print(text, logprob)\n",
    "#     print(text)\n",
    "#     for token, logprob in logprob.items():\n",
    "#         # Print with tab and escaping newlines\n",
    "#         print(\"   \", token.replace(\"\\n\", \"\\\\n\"), logprob)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "' cat, dog '",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113512/2972925650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m }\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m classifications, usages = get_classifications(\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m )\n",
      "\u001b[0;32m/tmp/ipykernel_113512/2972925650.py\u001b[0m in \u001b[0;36mget_classifications\u001b[0;34m(texts, classes, model, batch_size, num_threads, max_tokens)\u001b[0m\n\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         return get_classifications_instruct(\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         )\n",
      "\u001b[0;32m/tmp/ipykernel_113512/2972925650.py\u001b[0m in \u001b[0;36mget_classifications_instruct\u001b[0;34m(texts, classes, model, batch_size, num_threads, max_tokens)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Create the prompts for each text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mprompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# Get the completions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_113512/2972925650.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Create the prompts for each text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mprompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# Get the completions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ' cat, dog '"
     ]
    }
   ],
   "source": [
    "from soda.openai.text import completion_model_batched, instruct_chat_model_batched\n",
    "\n",
    "\n",
    "def get_classifications(\n",
    "    texts, classes, model, batch_size=1, num_threads=1, max_tokens=1\n",
    "):\n",
    "    if \"gpt-4\" in model or model == \"gpt-3.5-turbo\" or model == \"gpt-3.5-turbo-0125\":\n",
    "        return get_classifications_gpt4(\n",
    "            texts, classes, model, batch_size, num_threads, max_tokens\n",
    "        )\n",
    "    else:\n",
    "        return get_classifications_instruct(\n",
    "            texts, classes, model, batch_size, num_threads, max_tokens\n",
    "        )\n",
    "\n",
    "\n",
    "def get_classifications_gpt4(\n",
    "    texts, classes, model, batch_size=1, num_threads=1, max_tokens=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the classification probabilities using the GPT-4 chat API\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the system message\n",
    "    system_message = \"\"\"\n",
    "You are a classification system. You will be given some text and you must respond with a single class that the text most likely belongs to. Ensure your response is only the class, with no other text.\n",
    "\"\"\".strip()\n",
    "    system_message += \"\\n\\n\"\n",
    "    for class_ in classes:\n",
    "        system_message += f\"*** Class '{class_}' ***\\n\"\n",
    "        system_message += classes[class_]\n",
    "        system_message += \"\\n\"\n",
    "\n",
    "    # Map the texts to the prompts\n",
    "    prompts = [\n",
    "        \"Text: \" + text + \"\\nClass (from { \" + \", \".join(classes.keys()) + \" }):\"\n",
    "        for text in texts\n",
    "    ]\n",
    "\n",
    "    # # Print a summary of the prompts\n",
    "    # for prompt in prompts:\n",
    "    #     print(\"--- System Message ---\")\n",
    "    #     print(system_message)\n",
    "    #     print()\n",
    "\n",
    "    #     print(\"--- Prompt ---\")\n",
    "    #     print(prompt)\n",
    "    #     print()\n",
    "    #     print()\n",
    "\n",
    "    # Get the completions\n",
    "    results = instruct_chat_model_batched(\n",
    "        system_message,\n",
    "        # texts,\n",
    "        prompts,\n",
    "        model,\n",
    "        num_threads=num_threads,\n",
    "        logprobs=True,\n",
    "        top_logprobs=min(5, len(classes)),\n",
    "        temperature=0.0,\n",
    "        timeout=5,\n",
    "    )\n",
    "\n",
    "    # Get the token logprobs for each completion\n",
    "    responses = [result.choices[0].logprobs.content[0] for result in results]\n",
    "    usages = [result.usage for result in results]\n",
    "\n",
    "    # For each class, get the logprobs for each token\n",
    "    # Use -inf for classes without an entry in the top logprobs\n",
    "    logprobs = []\n",
    "    for response in responses:\n",
    "        classification = {class_: -float(\"inf\") for class_ in classes}\n",
    "\n",
    "        # Get the logprobs for each token\n",
    "        # for token, logprob in response.items():\n",
    "        for top_logprob in response.top_logprobs:\n",
    "            # Get the class for this token\n",
    "            class_ = top_logprob.token.strip()\n",
    "\n",
    "            # Update the classification\n",
    "            classification[class_] = top_logprob.logprob\n",
    "\n",
    "        logprobs.append(classification)\n",
    "\n",
    "    return logprobs, usages\n",
    "\n",
    "\n",
    "def get_classifications_instruct(\n",
    "    texts, classes, model, batch_size=1, num_threads=1, max_tokens=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the classification probabilities for each text and class.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = \"\"\n",
    "    prompt += \"You are a classification system. Given the text below, you will classify it into either of the given classes. Output the class name.\\n\"\n",
    "    # prompt += \"You are a classification system. Given the text below, you will classify it into one of the following classes. If no class is suitable, choose \\\"none\\\". If more than one class is suitable, choose \\\"all\\\". Ensure you match the classes exactly, including wording and casing.\\n\"\n",
    "    # for class_ in classes:\n",
    "    #     prompt += f\"- {class_}\\n\"\n",
    "    # for class_, description in classes.items():\n",
    "    #     prompt += f\"- {class_}: {description}\\n\"\n",
    "    # prompt += \"*** Class 'a' ***\\n\"\n",
    "    # prompt += classes[\"a\"]\n",
    "    # prompt += \"\\n\"\n",
    "\n",
    "    # prompt += \"*** Class 'b' ***\\n\"\n",
    "    # prompt += classes[\"b\"]\n",
    "    # prompt += \"\\n\"\n",
    "\n",
    "    for class_ in classes:\n",
    "        prompt += f\"*** Class '{class_}' ***\\n\"\n",
    "        prompt += classes[class_]\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "    prompt += \"\\nText: {TEXT}\\nClass (from { \" + \", \".join(classes.keys()) + \" }):\"\n",
    "\n",
    "    # Create the prompts for each text\n",
    "    prompts = [prompt.format(TEXT=text) for text in texts]\n",
    "\n",
    "    # Get the completions\n",
    "    completions = completion_model_batched(\n",
    "        prompts,\n",
    "        model,\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_threads,\n",
    "        max_tokens=max_tokens,\n",
    "        logprobs=2,\n",
    "    )\n",
    "    # print(completions)\n",
    "\n",
    "    usages = [completion.usage for completion in completions]\n",
    "\n",
    "    # Get the token logprobs for each completion\n",
    "    logprobs = []\n",
    "    # For each class, get the logprobs for each token\n",
    "    # Use -inf for classes without an entry in the top logprobs\n",
    "    for completion in completions.choices:\n",
    "        print(completion)\n",
    "        classification = {class_: -float(\"inf\") for class_ in classes}\n",
    "\n",
    "        # Get the logprobs for each token\n",
    "        for token, logprob in completion.logprobs.top_logprobs[0].items():\n",
    "            # Get the class for this token\n",
    "            class_ = token.strip().replace(\"▁\", \"\")\n",
    "\n",
    "            # Update the classification\n",
    "            # classification[class_] = logprob\n",
    "\n",
    "            # There might be duplicates due to the ▁ character that DF seems to use\n",
    "            if class_ not in classification:\n",
    "                classification[class_] = logprob\n",
    "\n",
    "            classification[class_] = max(\n",
    "                classification.get(class_, -float(\"inf\")), logprob\n",
    "            )\n",
    "\n",
    "        logprobs.append(classification)\n",
    "\n",
    "    return logprobs, usages\n",
    "\n",
    "\n",
    "# Classify a simple dataset about cats and dogs\n",
    "# texts = [\"This is a cat\", \"This is a dog\", \"This is a cat, and this is a dog\"]\n",
    "texts = [\n",
    "    \"This is a cat\",\n",
    "    \"This is a dog\",\n",
    "    \"This is a cat, and this is a dog\",\n",
    "    \"We're not talking about cats and dogs here!\",\n",
    "]\n",
    "# classes = [\"cat\", \"dog\"]\n",
    "classes = {\n",
    "    \"cat\": \"Discusses a cat\",\n",
    "    \"dog\": \"Discusses a dog\",\n",
    "}\n",
    "\n",
    "classifications, usages = get_classifications(\n",
    "    texts, classes, MODEL, batch_size=1, num_threads=2, max_tokens=1\n",
    ")\n",
    "\n",
    "print(classifications)\n",
    "prompt_tokens = sum(usage.prompt_tokens for usage in usages)\n",
    "completion_tokens = sum(usage.completion_tokens for usage in usages)\n",
    "print(\"Prompt tokens:\", prompt_tokens)\n",
    "print(\"Completion token:\", completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing with joblib\n",
    "import os\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "# # Load texts from corpora/{CORPUS}.json\n",
    "# with open(os.path.join(\"../corpora\", f\"{CORPUS}.json\"), \"r\") as f:\n",
    "#     corpus_data = yaml.safe_load(f)\n",
    "\n",
    "# with open(CORPUS, \"r\") as f:\n",
    "#     corpus_data = yaml.safe_load(f)\n",
    "\n",
    "# seeds = corpus_data[\"seeds\"]\n",
    "# distilled = corpus_data[\"distilled\"]\n",
    "# summarized = corpus_data[\"summarized\"]\n",
    "# names = corpus_data[\"names\"]\n",
    "# dataset = corpus_data[\"dataset\"]\n",
    "\n",
    "# # Convert the dataset to corpus data format\n",
    "# corpus_data = []\n",
    "# for seed_set in dataset:\n",
    "#     for a in seed_set[\"a_first\"][\"a\"]:\n",
    "#         corpus_data.append({\"text\": a, \"speakername\": \"a\"})\n",
    "#     for b in seed_set[\"a_first\"][\"b\"]:\n",
    "#         corpus_data.append({\"text\": b, \"speakername\": \"b\"})\n",
    "#     for a in seed_set[\"b_first\"][\"a\"]:\n",
    "#         corpus_data.append({\"text\": a, \"speakername\": \"a\"})\n",
    "#     for b in seed_set[\"b_first\"][\"b\"]:\n",
    "#         corpus_data.append({\"text\": b, \"speakername\": \"b\"})\n",
    "\n",
    "# # Shuffle\n",
    "# random.shuffle(corpus_data)\n",
    "\n",
    "# print(\"Loaded {} texts from corpus\".format(len(corpus_data)))\n",
    "# print(\"Total word count:\", sum([len(text[\"text\"].split()) for text in corpus_data]))\n",
    "\n",
    "# # Create the training data\n",
    "# X = [text[\"text\"] for text in corpus_data]\n",
    "# y = [text[\"speakername\"] for text in corpus_data]\n",
    "# print(len(X), len(y))\n",
    "\n",
    "from import_data import import_data\n",
    "X, y, seeds, distilled, summarized, names = import_data(CORPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = {\n",
    "#     \"a\": \"A helpful statement.\",\n",
    "#     \"b\": \"An unhelpful statement.\",\n",
    "# }\n",
    "\n",
    "# Construct the classes depending on the mode\n",
    "a_desc = \"\"\n",
    "b_desc = \"\"\n",
    "if MODE == \"seeds\":\n",
    "    a_desc = \"\\n\"\n",
    "    b_desc = \"\\n\"\n",
    "    for seed in seeds:\n",
    "        a_desc += \"  \" + seed[\"a\"] + \"\\n\"\n",
    "        b_desc += \"  \" + seed[\"b\"] + \"\\n\"\n",
    "elif MODE == \"distilled\":\n",
    "    a_desc = \"\\n\"\n",
    "    b_desc = \"\\n\"\n",
    "    for seed in distilled:\n",
    "        a_desc += \"  \" + seed[\"a\"] + \"\\n\"\n",
    "        b_desc += \"  \" + seed[\"b\"] + \"\\n\"\n",
    "elif MODE == \"summaries\":\n",
    "    a_desc = summarized[\"a\"]\n",
    "    b_desc = summarized[\"b\"]\n",
    "elif MODE == \"zero-shot\":\n",
    "    a_desc = \"A helpful statement.\"\n",
    "    b_desc = \"An unhelpful statement.\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown mode: {MODE}\")\n",
    "\n",
    "# Define the classes\n",
    "# classes = {\n",
    "#     \"a\": a_desc,\n",
    "#     \"b\": b_desc,\n",
    "# }\n",
    "classes = {\n",
    "    names[\"a\"]: a_desc,\n",
    "    names[\"b\"]: b_desc,\n",
    "}\n",
    "\n",
    "# Get the classifications\n",
    "classifications, usages = get_classifications(\n",
    "    # X, classes, MODEL, batch_size=20, num_threads=50, max_tokens=1\n",
    "    X,\n",
    "    classes,\n",
    "    MODEL,\n",
    "    batch_size=1,\n",
    "    # num_threads=50,\n",
    "    num_threads=20,\n",
    "    max_tokens=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the usage\n",
    "prompt_tokens = sum(usage.prompt_tokens for usage in usages)\n",
    "completion_tokens = sum(usage.completion_tokens for usage in usages)\n",
    "print(\"Prompt tokens:\", prompt_tokens)\n",
    "print(\"Completion token:\", completion_tokens)\n",
    "\n",
    "# Estimate cost given the model\n",
    "c_prompt = -1\n",
    "c_completion = -1\n",
    "if \"gpt-4\" in MODEL:\n",
    "    c_prompt = 0.01 / 1000\n",
    "    c_completion = 0.03 / 1000\n",
    "elif \"gpt-3.5-turbo\" in MODEL:\n",
    "    c_prompt = 0.0005 / 1000\n",
    "    c_completion = 0.0015 / 1000\n",
    "\n",
    "# Estimate cost\n",
    "cost = c_prompt * prompt_tokens + c_completion * completion_tokens\n",
    "if cost >= 0:\n",
    "    print(\"Cost estimate: ${:.3f}\".format(cost))\n",
    "else:\n",
    "    print(\"No cost estimate available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory\n",
    "directory = os.path.join(\"corpus_results\", \"gpt\", MODEL, CORPUS_NAME, MODE + \"/\")\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the data in CSV format\n",
    "print(classifications[0])\n",
    "data = []\n",
    "total = 0\n",
    "correct = 0\n",
    "# incorrect_map = {\"myth\": 0, \"science\": 0}\n",
    "# correct_map = {\"myth\": 0, \"science\": 0}\n",
    "\n",
    "# Generic\n",
    "incorrect_map = {class_: 0 for class_ in classes}\n",
    "correct_map = {class_: 0 for class_ in classes}\n",
    "\n",
    "print(correct_map)\n",
    "print(incorrect_map)\n",
    "\n",
    "a_name = names[\"a\"]\n",
    "b_name = names[\"b\"]\n",
    "\n",
    "for text, truth, classification in tqdm(zip(X, y, classifications), total=len(X)):\n",
    "    print(text, truth, classification)\n",
    "    # # Add the data\n",
    "    # data.append(\n",
    "    #     {\n",
    "    #         \"text\": text,\n",
    "    #         # \"myth\": classification[\"myth\"],\n",
    "    #         \"myth\": min(\n",
    "    #             classification.get(\"myth\", -float(\"inf\")),\n",
    "    #             classification.get(\"my\", -float(\"inf\")),\n",
    "    #         ),\n",
    "    #         \"science\": classification[\"science\"],\n",
    "    #         \"classification\": max(classification, key=classification.get),\n",
    "    #         \"truth\": truth,\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    # Map truth to the name\n",
    "    if truth == \"a\":\n",
    "        truth = a_name\n",
    "    elif truth == \"b\":\n",
    "        truth = b_name\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown truth: {truth}\")\n",
    "\n",
    "    # Add the data (class-agnostic)\n",
    "    datum = {\n",
    "        \"text\": text,\n",
    "        \"truth\": truth,\n",
    "        \"classification\": max(classification, key=classification.get),\n",
    "    }\n",
    "    # datum.update(classification)\n",
    "    data.append(datum)\n",
    "\n",
    "    # # if max(classification, key=classification.get) == truth:\n",
    "    # if data[-1][\"classification\"] == truth:\n",
    "    #     correct += 1\n",
    "    #     correct_map[truth] += 1\n",
    "    # else:\n",
    "    #     incorrect_map[truth] += 1\n",
    "\n",
    "    # The classification will be a prefix of one of the classes\n",
    "    # Find the class with that prefix (throw an error if there's more than one match)\n",
    "    # maximum = max(classification, key=classification.get)\n",
    "\n",
    "    # Find the match\n",
    "    # match = None\n",
    "    # for class_ in classes:\n",
    "    #     if class_.startswith(classification):\n",
    "    #         if match is not None:\n",
    "    #             raise ValueError(f\"Multiple matches for {classification}\")\n",
    "    #         match = class_\n",
    "\n",
    "    matches = {}\n",
    "    for class_ in classes:\n",
    "        matches[class_] = float(\"-inf\")\n",
    "        for token in classification:\n",
    "            if class_.startswith(token):\n",
    "                matches[class_] = max(matches[class_], classification[token])\n",
    "\n",
    "    # Get the best match\n",
    "    # print(\"Matches:\", matches)\n",
    "    match = max(matches, key=lambda k: matches[k])\n",
    "\n",
    "    # Update the datum\n",
    "    data[-1][\"classification\"] = match\n",
    "\n",
    "    # Update the counts\n",
    "    if match == truth:\n",
    "        correct += 1\n",
    "        correct_map[truth] += 1\n",
    "    else:\n",
    "        incorrect_map[truth] += 1\n",
    "\n",
    "    # Assign the match to the classification\n",
    "    total += 1\n",
    "\n",
    "# Save to CSV\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(\"corpus_results\", f\"{EXPERIMENT_NAME}.csv\"), index=False)\n",
    "\n",
    "# Show accuracy and incorrect counts\n",
    "print(\"Accuracy:\", correct / total)\n",
    "print(\"Incorrect counts:\", incorrect_map)\n",
    "\n",
    "# Show a confusion matrix as a pandas df\n",
    "import pandas as pd\n",
    "\n",
    "# Get the confusion matrix\n",
    "confusion_matrix = pd.crosstab(\n",
    "    df[\"truth\"], df[\"classification\"], rownames=[\"Truth\"], colnames=[\"Classification\"]\n",
    ")\n",
    "\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Convert to percentages\n",
    "confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=0)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Save confusion matrix and data to corpus_results/classifiers/{EXPERIMENT_NAME}\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "\n",
    "# Save the confusion matrix\n",
    "confusion_matrix.to_csv(os.path.join(directory, \"confusion_matrix.csv\"))\n",
    "\n",
    "# Save the data\n",
    "df.to_csv(os.path.join(directory, \"data.csv\"), index=False)\n",
    "\n",
    "# Save the usage data as a CSV\n",
    "usage_data = []\n",
    "for usage in usages:\n",
    "    usage_data.append(\n",
    "        {\n",
    "            \"prompt_tokens\": usage.prompt_tokens,\n",
    "            \"completion_tokens\": usage.completion_tokens,\n",
    "        }\n",
    "    )\n",
    "\n",
    "usage_df = pd.DataFrame(usage_data)\n",
    "usage_df.to_csv(os.path.join(directory, \"usage.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
