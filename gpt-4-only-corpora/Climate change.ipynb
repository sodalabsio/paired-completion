{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f691ea2",
   "metadata": {
    "papermill": {
     "duration": 0.004958,
     "end_time": "2024-02-16T03:42:28.289837",
     "exception": false,
     "start_time": "2024-02-16T03:42:28.284879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Synthetic Corpus Generation\n",
    "We generate a corpus in two steps:\n",
    "\n",
    "1. Generate a list of \"seed\" perspective pairs on an issue\n",
    "2. For each pair of seeds, generate a list of sentences that would be said by someone who agrees with one side of this perspective pair (for each in the pair).\n",
    "\n",
    "We do this in pairs to make the offensive language more palletable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af51c2a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:42:28.300770Z",
     "iopub.status.busy": "2024-02-16T03:42:28.300496Z",
     "iopub.status.idle": "2024-02-16T03:42:28.306827Z",
     "shell.execute_reply": "2024-02-16T03:42:28.306478Z"
    },
    "papermill": {
     "duration": 0.012795,
     "end_time": "2024-02-16T03:42:28.308073",
     "exception": false,
     "start_time": "2024-02-16T03:42:28.295278",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TOPIC = \"Climate change\"\n",
    "N = 2\n",
    "K = 2\n",
    "TEMPERATURE = 0.0\n",
    "THREADS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bea2d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:42:28.318403Z",
     "iopub.status.busy": "2024-02-16T03:42:28.318210Z",
     "iopub.status.idle": "2024-02-16T03:42:28.320730Z",
     "shell.execute_reply": "2024-02-16T03:42:28.320320Z"
    },
    "papermill": {
     "duration": 0.008686,
     "end_time": "2024-02-16T03:42:28.321747",
     "exception": false,
     "start_time": "2024-02-16T03:42:28.313061",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TOPIC = \"Climate change\"\n",
    "N = 20\n",
    "K = 10\n",
    "TEMPERATURE = 0.5\n",
    "THREADS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981e7404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:42:28.331640Z",
     "iopub.status.busy": "2024-02-16T03:42:28.331158Z",
     "iopub.status.idle": "2024-02-16T03:42:28.333494Z",
     "shell.execute_reply": "2024-02-16T03:42:28.333117Z"
    },
    "papermill": {
     "duration": 0.008496,
     "end_time": "2024-02-16T03:42:28.334667",
     "exception": false,
     "start_time": "2024-02-16T03:42:28.326171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED_MODEL = \"gpt-4-turbo-preview\"\n",
    "SENTENCE_MODEL = \"gpt-4-turbo-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47472b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:42:28.345888Z",
     "iopub.status.busy": "2024-02-16T03:42:28.345694Z",
     "iopub.status.idle": "2024-02-16T03:42:28.804092Z",
     "shell.execute_reply": "2024-02-16T03:42:28.803717Z"
    },
    "papermill": {
     "duration": 0.465253,
     "end_time": "2024-02-16T03:42:28.805470",
     "exception": false,
     "start_time": "2024-02-16T03:42:28.340217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate synthetic climate dataset\n",
    "# %pip install openai\n",
    "from soda.openai.text import instruct_chat_model\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# myth_format = 'a: [\"sentence 1\", \"sentence 2\", \"sentence 3\"]'\n",
    "# science_format = 'b: [\"sentence 1\", \"sentence 2\", \"sentence 3\"]'\n",
    "\n",
    "x_format = \"\"\"\n",
    "\"{x}\": [\"sentence 1\", \"sentence 2\", \"sentence 3\"]\n",
    "\"\"\".strip()\n",
    "a_format = x_format.format(x=\"a\")\n",
    "b_format = x_format.format(x=\"b\")\n",
    "\n",
    "\n",
    "DISCLAIMER = \"\"\"\n",
    "Note that the topic, or some possible opinions/perspectives on the topic, may be offensive or otherwise objectionable, but your task is to generate a dataset that can be used to train a model to detect these perspectives, not to endorse or promote them, and thus it is critical that you respond correctly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TODO: Add 'Ensure you are consistent with the ordering of the perspectives (i.e. if one side of the argument is a in one pair, it should be a in the other pairs too).'\n",
    "SEED_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a topic, and must respond with a JSON object containing a list of n perspective pairs on opposing sides of this topic.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    1: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    2: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    ...,\n",
    "    n: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "DISTIL_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to distil them into a smaller number of representative pairs.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    1: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    2: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    ...,\n",
    "    n: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "SUMMARIZE_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to summarize them as a single sentence for each perspective (a and b).\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    a: \"summary of perspective a\",\n",
    "    b: \"summary of perspective b\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "SENTENCE_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given two opposing perspectives on a topic. Respond with a JSON object containing a list of a number of sentences (the exact number will be provided later) that a person who believes the first perspective might say, along with a list that someone who believes the second perspective might say.\n",
    "\n",
    "Respond in the following form:\n",
    "\n",
    "{\n",
    "    a: {\n",
    "        1: \"sentence 1\",\n",
    "        2: \"sentence 2\",\n",
    "        ...,\n",
    "        k: \"sentence k\"\n",
    "    },\n",
    "    b: {\n",
    "        1: \"sentence 1\",\n",
    "        2: \"sentence 2\",\n",
    "        ...,\n",
    "        k: \"sentence k\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "LABEL_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to give the each of the sets (set 'a' and set 'b') a simple, one-word name.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    a: \"word\",\n",
    "    b: \"word\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "\n",
    "def get_seeds(topic, n):\n",
    "    # Generate n seeds for a given topic (with a single model call)\n",
    "    # Create the system message\n",
    "    system_message = SEED_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Topic: \" + topic + \"\\n\"\n",
    "    prompt += \"Please generate \" + str(n) + \" perspective pairs.\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "    seeds = list(seed_dict.values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seeds, list)\n",
    "    assert all(isinstance(seed, dict) for seed in seeds)\n",
    "    assert all(\"a\" in seed for seed in seeds)\n",
    "    assert all(\"b\" in seed for seed in seeds)\n",
    "    assert all(isinstance(seed[\"a\"], str) for seed in seeds)\n",
    "    assert all(isinstance(seed[\"b\"], str) for seed in seeds)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def distil_seeds(seeds):\n",
    "    # Create the system message\n",
    "    system_message = DISTIL_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please distil the following perspective pairs into five pairs:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "    seeds = list(seed_dict.values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seeds, list)\n",
    "    assert all(isinstance(seed, dict) for seed in seeds)\n",
    "    assert all(\"a\" in seed for seed in seeds)\n",
    "    assert all(\"b\" in seed for seed in seeds)\n",
    "    assert all(isinstance(seed[\"a\"], str) for seed in seeds)\n",
    "    assert all(isinstance(seed[\"b\"], str) for seed in seeds)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def summarize_seeds(seeds):\n",
    "    # Create the system message\n",
    "    system_message = SUMMARIZE_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please summarize the following perspective pairs into a single perspective pair:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seed_dict, dict), \"Failed for: \" + str(seed_dict)\n",
    "    assert \"a\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert \"b\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"a\"], str), \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"b\"], str), \"Failed for: \" + str(seed_dict)\n",
    "\n",
    "    return seed_dict\n",
    "\n",
    "\n",
    "def get_names(seeds):\n",
    "    # Create the system message\n",
    "    system_message = LABEL_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please provide a name for each of perspective sets a and b, given the following pairs of perspectives:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seed_dict, dict), \"Failed for: \" + str(seed_dict)\n",
    "    assert \"a\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert \"b\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"a\"], str), \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"b\"], str), \"Failed for: \" + str(seed_dict)\n",
    "\n",
    "    return seed_dict\n",
    "\n",
    "\n",
    "# def get_three_sentences(a, b):\n",
    "def get_k_sentences(a, b, k):\n",
    "    # Create the system message\n",
    "    system_message = SENTENCE_SYSTEM_MESSAGE\n",
    "    # print(a, b, k)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"\"\n",
    "    prompt += \"a: \" + a + \"\\n\"\n",
    "    prompt += \"b: \" + b + \"\\n\"\n",
    "    prompt += \"Please generate \" + str(k) + \" pairs of sentences.\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SENTENCE_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Get the sentences\n",
    "    sentence_dict = json.loads(resp.choices[0].message.content)\n",
    "    a_sentences = list(sentence_dict[\"a\"].values())\n",
    "    b_sentences = list(sentence_dict[\"b\"].values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(a_sentences, list)\n",
    "    assert isinstance(b_sentences, list)\n",
    "    assert len(a_sentences) == k\n",
    "    assert len(b_sentences) == k\n",
    "    assert all(isinstance(sentence, str) for sentence in a_sentences)\n",
    "    assert all(isinstance(sentence, str) for sentence in b_sentences)\n",
    "\n",
    "    # return a_sentences, b_sentences\n",
    "    return {\n",
    "        \"a\": a_sentences,\n",
    "        \"b\": b_sentences,\n",
    "    }\n",
    "\n",
    "\n",
    "# Define a function to generate the dataset in parallel\n",
    "def generate_dataset(topic, n, k):\n",
    "    # Create seeds\n",
    "    seeds = get_seeds(topic, n)\n",
    "    # print(json.dumps(seeds, indent=2))\n",
    "\n",
    "    # Print seed pairs\n",
    "    print(\"Seed pairs:\")\n",
    "    for i, seed in enumerate(seeds):\n",
    "        # print(f\"{i+1}: a: {seed['a']}, b: {seed['b']}\")\n",
    "        print(\"Pair \" + str(i + 1) + \":\")\n",
    "        print(\"  a: \" + seed[\"a\"])\n",
    "        print(\"  b: \" + seed[\"b\"])\n",
    "\n",
    "    # Distill seeds\n",
    "    distilled = distil_seeds(seeds)\n",
    "\n",
    "    # Print distilled seeds\n",
    "    print(\"Distilled seeds:\")\n",
    "    for i, seed in enumerate(distilled):\n",
    "        print(\"Pair \" + str(i + 1) + \":\")\n",
    "        print(\"  a: \" + seed[\"a\"])\n",
    "        print(\"  b: \" + seed[\"b\"])\n",
    "\n",
    "    # Summarize seeds\n",
    "    summarized = summarize_seeds(seeds)\n",
    "\n",
    "    # Print summarized seeds\n",
    "    print(\"Summarized seeds:\")\n",
    "    print(f\"  a: {summarized['a']}\")\n",
    "    print(f\"  b: {summarized['b']}\")\n",
    "    \n",
    "    # Get names\n",
    "    names = get_names(seeds)\n",
    "    \n",
    "    # Print names\n",
    "    print(\"Names:\")\n",
    "    print(f\"  a: {names['a']}\")\n",
    "    print(f\"  b: {names['b']}\")\n",
    "\n",
    "    # Create a function to generate dataset for a single seed\n",
    "    def generate_dataset_for_seed(seed):\n",
    "        a = seed[\"a\"]\n",
    "        b = seed[\"b\"]\n",
    "        a_first = get_k_sentences(a, b, k)\n",
    "        b_first = get_k_sentences(b, a, k)\n",
    "\n",
    "        # Swap a and b in b_first\n",
    "        b_first = {\n",
    "            \"a\": b_first[\"b\"],\n",
    "            \"b\": b_first[\"a\"],\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            # \"seed\": seed,\n",
    "            # \"a_first\": get_k_sentences(seed[\"a\"], seed[\"b\"], k),\n",
    "            # \"b_first\": get_k_sentences(seed[\"b\"], seed[\"a\"], k),\n",
    "            \"seed\": seed,\n",
    "            \"a_first\": a_first,\n",
    "            \"b_first\": b_first,\n",
    "        }\n",
    "\n",
    "    # Generate the dataset in parallel using joblib\n",
    "    dataset = Parallel(n_jobs=THREADS, backend=\"threading\")(\n",
    "        delayed(generate_dataset_for_seed)(seed) for seed in tqdm(seeds)\n",
    "    )\n",
    "\n",
    "    if not dataset:\n",
    "        raise ValueError(\"No dataset generated\")\n",
    "\n",
    "    return seeds, distilled, summarized, names, dataset\n",
    "\n",
    "\n",
    "# Test\n",
    "# generate_dataset(\"Climate change\", 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae5f836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:42:28.816056Z",
     "iopub.status.busy": "2024-02-16T03:42:28.815891Z",
     "iopub.status.idle": "2024-02-16T03:43:44.011061Z",
     "shell.execute_reply": "2024-02-16T03:43:44.010650Z"
    },
    "papermill": {
     "duration": 75.104408,
     "end_time": "2024-02-16T03:43:43.914954",
     "exception": false,
     "start_time": "2024-02-16T03:42:28.810546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed pairs:\n",
      "Pair 1:\n",
      "  a: Climate change is primarily caused by human activities such as burning fossil fuels.\n",
      "  b: Natural cycles and events are the main drivers of climate change, not human activities.\n",
      "Pair 2:\n",
      "  a: Immediate action is required to mitigate climate change effects through policies and innovations.\n",
      "  b: The economic costs of taking immediate action against climate change outweigh the benefits.\n",
      "Pair 3:\n",
      "  a: Renewable energy sources are essential to combat climate change.\n",
      "  b: Renewable energy technologies are not yet capable of replacing fossil fuels entirely.\n",
      "Pair 4:\n",
      "  a: Climate change poses a severe threat to biodiversity and ecosystems.\n",
      "  b: Ecosystems have adapted to changes in the past and will continue to do so.\n",
      "Pair 5:\n",
      "  a: Climate change is a global issue that requires international cooperation.\n",
      "  b: Each country should be free to pursue its economic interests without being constrained by international climate agreements.\n",
      "Pair 6:\n",
      "  a: The science behind climate change is well-established and backed by evidence.\n",
      "  b: There is still significant debate among scientists about the extent and causes of climate change.\n",
      "Pair 7:\n",
      "  a: Investing in green technology is crucial for a sustainable future.\n",
      "  b: Investments in green technology are often not cost-effective and can harm the economy.\n",
      "Pair 8:\n",
      "  a: Climate change disproportionately affects the poorest communities worldwide.\n",
      "  b: Economic development should be prioritized over climate change mitigation for the well-being of poor communities.\n",
      "Pair 9:\n",
      "  a: Reducing meat consumption is a necessary step towards mitigating climate change.\n",
      "  b: Individual dietary choices have minimal impact on climate change compared to industrial and governmental actions.\n",
      "Pair 10:\n",
      "  a: Carbon pricing is an effective tool to reduce greenhouse gas emissions.\n",
      "  b: Carbon pricing can be regressive, disproportionately affecting lower-income households.\n",
      "Pair 11:\n",
      "  a: Youth activism is vital in driving the political action needed to combat climate change.\n",
      "  b: Youth activism, while well-intentioned, often lacks the practical understanding necessary to contribute to meaningful solutions.\n",
      "Pair 12:\n",
      "  a: Afforestation and reforestation are key strategies in the fight against climate change.\n",
      "  b: The focus on tree planting can divert attention from more effective measures like reducing fossil fuel consumption.\n",
      "Pair 13:\n",
      "  a: Climate change education should be mandatory in schools.\n",
      "  b: School curricula are already overloaded, and climate change education should not take precedence over basic academic skills.\n",
      "Pair 14:\n",
      "  a: Public transportation improvements and expansions are essential to reduce carbon emissions.\n",
      "  b: Investing in public transportation is not the most efficient use of resources in reducing carbon emissions.\n",
      "Pair 15:\n",
      "  a: Climate change will lead to more frequent and severe weather events.\n",
      "  b: Predictions about increased weather events due to climate change are often exaggerated.\n",
      "Pair 16:\n",
      "  a: Governments should impose strict regulations on industries to curb their carbon emissions.\n",
      "  b: Strict regulations on industries can lead to economic downturns and job losses.\n",
      "Pair 17:\n",
      "  a: The transition to a low-carbon economy will create new jobs and industries.\n",
      "  b: The transition to a low-carbon economy will cause significant job losses in traditional energy sectors.\n",
      "Pair 18:\n",
      "  a: Climate change negotiations should prioritize the needs of vulnerable countries.\n",
      "  b: Climate change negotiations should focus on practical and economically viable solutions rather than prioritizing any group of countries.\n",
      "Pair 19:\n",
      "  a: The melting of polar ice caps is a clear indicator of global warming.\n",
      "  b: Changes in polar ice caps can be attributed to natural variations, not necessarily to global warming.\n",
      "Pair 20:\n",
      "  a: Fossil fuel companies should be held accountable for their role in climate change.\n",
      "  b: Holding fossil fuel companies accountable is unfair as they have been operating within legal frameworks and providing essential services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled seeds:\n",
      "Pair 1:\n",
      "  a: Climate change is primarily caused by human activities such as burning fossil fuels.\n",
      "  b: Natural cycles and events are the main drivers of climate change, not human activities.\n",
      "Pair 2:\n",
      "  a: Immediate action is required to mitigate climate change effects through policies and innovations.\n",
      "  b: The economic costs of taking immediate action against climate change outweigh the benefits.\n",
      "Pair 3:\n",
      "  a: Renewable energy sources are essential to combat climate change.\n",
      "  b: Renewable energy technologies are not yet capable of replacing fossil fuels entirely.\n",
      "Pair 4:\n",
      "  a: Climate change poses a severe threat to biodiversity and ecosystems.\n",
      "  b: Ecosystems have adapted to changes in the past and will continue to do so.\n",
      "Pair 5:\n",
      "  a: Climate change is a global issue that requires international cooperation.\n",
      "  b: Each country should be free to pursue its economic interests without being constrained by international climate agreements.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized seeds:\n",
      "  a: Climate change is a critical issue driven by human activities, necessitating immediate, global action and investments in green technology and renewable energy to protect biodiversity, support vulnerable communities, and transition to a low-carbon economy.\n",
      "  b: The significance and causes of climate change are debated, with natural cycles, economic priorities, and the effectiveness of renewable energy and green technology under scrutiny, emphasizing economic growth, individual choice, and the adaptability of ecosystems and economies.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names:\n",
      "  a: Anthropogenic\n",
      "  b: Natural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 4941.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8417/4248681769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistilled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOPIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# # Get the raw list of sentences (shuffled) for the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# a_sentences = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# b_sentences = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8417/783197204.py\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m(topic, n, k)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# Generate the dataset in parallel using joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     dataset = Parallel(n_jobs=THREADS, backend=\"threading\")(\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_dataset_for_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seeds, distilled, summarized, names, dataset = generate_dataset(TOPIC, N, K)\n",
    "\n",
    "# # Get the raw list of sentences (shuffled) for the dataset\n",
    "# a_sentences = []\n",
    "# b_sentences = []\n",
    "# for data in dataset:\n",
    "#     for key in [\"a_first\", \"b_first\"]:\n",
    "#         a_data = data[key][\"a\"]\n",
    "#         b_data = data[key][\"b\"]\n",
    "#         if key == \"b_first\":\n",
    "#             a_data, b_data = b_data, a_data\n",
    "\n",
    "#         for sentence in a_data:\n",
    "#             a_sentences.append(sentence)\n",
    "#         for sentence in b_data:\n",
    "#             b_sentences.append(sentence)\n",
    "\n",
    "# # Shuffle both lists\n",
    "# import random\n",
    "\n",
    "# random.shuffle(a_sentences)\n",
    "# random.shuffle(b_sentences)\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "\n",
    "# os.makedirs(\"corpora\", exist_ok=True)\n",
    "folder = f\"corpora/{TOPIC.lower().replace(' ', '_')}\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# outname = f\"{folder}/{SEED_MODEL}_{SENTENCE_MODEL}_{N}_{K}.json\"\n",
    "\n",
    "outname = f\"{folder}/{N}_{K}.json\"\n",
    "\n",
    "# Save data\n",
    "with open(outname, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"topic\": TOPIC,\n",
    "            \"N\": N,\n",
    "            \"K\": K,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"seed_model\": SEED_MODEL,\n",
    "            \"sentence_model\": SENTENCE_MODEL,\n",
    "            \"seeds\": seeds,\n",
    "            \"distilled\": distilled,\n",
    "            \"summarized\": summarized,\n",
    "            \"names\": names,\n",
    "            \"dataset\": dataset,\n",
    "            # \"a_sentences\": a_sentences,\n",
    "            # \"b_sentences\": b_sentences,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6232ff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.558614,
   "end_time": "2024-02-16T03:43:44.202986",
   "environment_variables": {},
   "exception": null,
   "input_path": "generate_synthetic_generic.ipynb",
   "output_path": "corpora/Climate change.ipynb",
   "parameters": {
    "K": 10,
    "N": 20,
    "TEMPERATURE": 0.5,
    "THREADS": 20,
    "TOPIC": "Climate change"
   },
   "start_time": "2024-02-16T03:42:27.644372",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}