{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91771f8",
   "metadata": {
    "papermill": {
     "duration": 0.004842,
     "end_time": "2024-02-16T03:21:47.814533",
     "exception": false,
     "start_time": "2024-02-16T03:21:47.809691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Synthetic Corpus Generation\n",
    "We generate a corpus in two steps:\n",
    "\n",
    "1. Generate a list of \"seed\" perspective pairs on an issue\n",
    "2. For each pair of seeds, generate a list of sentences that would be said by someone who agrees with one side of this perspective pair (for each in the pair).\n",
    "\n",
    "We do this in pairs to make the offensive language more palletable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fa2fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:21:47.825430Z",
     "iopub.status.busy": "2024-02-16T03:21:47.825040Z",
     "iopub.status.idle": "2024-02-16T03:21:47.831668Z",
     "shell.execute_reply": "2024-02-16T03:21:47.831315Z"
    },
    "papermill": {
     "duration": 0.012906,
     "end_time": "2024-02-16T03:21:47.832887",
     "exception": false,
     "start_time": "2024-02-16T03:21:47.819981",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TOPIC = \"Climate change\"\n",
    "N = 2\n",
    "K = 2\n",
    "TEMPERATURE = 0.0\n",
    "THREADS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7018d095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:21:47.842399Z",
     "iopub.status.busy": "2024-02-16T03:21:47.842066Z",
     "iopub.status.idle": "2024-02-16T03:21:47.844296Z",
     "shell.execute_reply": "2024-02-16T03:21:47.843979Z"
    },
    "papermill": {
     "duration": 0.008116,
     "end_time": "2024-02-16T03:21:47.845430",
     "exception": false,
     "start_time": "2024-02-16T03:21:47.837314",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TOPIC = \"Domestic violence\"\n",
    "N = 20\n",
    "K = 10\n",
    "TEMPERATURE = 0.5\n",
    "THREADS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccab784e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:21:47.854886Z",
     "iopub.status.busy": "2024-02-16T03:21:47.854576Z",
     "iopub.status.idle": "2024-02-16T03:21:47.856557Z",
     "shell.execute_reply": "2024-02-16T03:21:47.856246Z"
    },
    "papermill": {
     "duration": 0.007881,
     "end_time": "2024-02-16T03:21:47.857721",
     "exception": false,
     "start_time": "2024-02-16T03:21:47.849840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED_MODEL = \"gpt-4-turbo-preview\"\n",
    "SENTENCE_MODEL = \"gpt-4-turbo-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23c214e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:21:47.868417Z",
     "iopub.status.busy": "2024-02-16T03:21:47.868223Z",
     "iopub.status.idle": "2024-02-16T03:21:48.330882Z",
     "shell.execute_reply": "2024-02-16T03:21:48.330494Z"
    },
    "papermill": {
     "duration": 0.469292,
     "end_time": "2024-02-16T03:21:48.332308",
     "exception": false,
     "start_time": "2024-02-16T03:21:47.863016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate synthetic climate dataset\n",
    "# %pip install openai\n",
    "from soda.openai.text import instruct_chat_model\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# myth_format = 'a: [\"sentence 1\", \"sentence 2\", \"sentence 3\"]'\n",
    "# science_format = 'b: [\"sentence 1\", \"sentence 2\", \"sentence 3\"]'\n",
    "\n",
    "x_format = \"\"\"\n",
    "\"{x}\": [\"sentence 1\", \"sentence 2\", \"sentence 3\"]\n",
    "\"\"\".strip()\n",
    "a_format = x_format.format(x=\"a\")\n",
    "b_format = x_format.format(x=\"b\")\n",
    "\n",
    "\n",
    "DISCLAIMER = \"\"\"\n",
    "Note that the topic, or some possible opinions/perspectives on the topic, may be offensive or otherwise objectionable, but your task is to generate a dataset that can be used to train a model to detect these perspectives, not to endorse or promote them, and thus it is critical that you respond correctly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TODO: Add 'Ensure you are consistent with the ordering of the perspectives (i.e. if one side of the argument is a in one pair, it should be a in the other pairs too).'\n",
    "SEED_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a topic, and must respond with a JSON object containing a list of n perspective pairs on opposing sides of this topic.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    1: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    2: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    ...,\n",
    "    n: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "DISTIL_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to distil them into a smaller number of representative pairs.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    1: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    2: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    ...,\n",
    "    n: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "SUMMARIZE_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to summarize them as a single sentence for each perspective (a and b).\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    a: \"summary of perspective a\",\n",
    "    b: \"summary of perspective b\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "SENTENCE_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given two opposing perspectives on a topic. Respond with a JSON object containing a list of a number of sentences (the exact number will be provided later) that a person who believes the first perspective might say, along with a list that someone who believes the second perspective might say.\n",
    "\n",
    "Respond in the following form:\n",
    "\n",
    "{\n",
    "    a: {\n",
    "        1: \"sentence 1\",\n",
    "        2: \"sentence 2\",\n",
    "        ...,\n",
    "        k: \"sentence k\"\n",
    "    },\n",
    "    b: {\n",
    "        1: \"sentence 1\",\n",
    "        2: \"sentence 2\",\n",
    "        ...,\n",
    "        k: \"sentence k\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "LABEL_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to give the each of the sets (set 'a' and set 'b') a simple, one-word name.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    a: \"word\",\n",
    "    b: \"word\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "\n",
    "def get_seeds(topic, n):\n",
    "    # Generate n seeds for a given topic (with a single model call)\n",
    "    # Create the system message\n",
    "    system_message = SEED_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Topic: \" + topic + \"\\n\"\n",
    "    prompt += \"Please generate \" + str(n) + \" perspective pairs.\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "    seeds = list(seed_dict.values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seeds, list)\n",
    "    assert all(isinstance(seed, dict) for seed in seeds)\n",
    "    assert all(\"a\" in seed for seed in seeds)\n",
    "    assert all(\"b\" in seed for seed in seeds)\n",
    "    assert all(isinstance(seed[\"a\"], str) for seed in seeds)\n",
    "    assert all(isinstance(seed[\"b\"], str) for seed in seeds)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def distil_seeds(seeds):\n",
    "    # Create the system message\n",
    "    system_message = DISTIL_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please distil the following perspective pairs into five pairs:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "    seeds = list(seed_dict.values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seeds, list)\n",
    "    assert all(isinstance(seed, dict) for seed in seeds)\n",
    "    assert all(\"a\" in seed for seed in seeds)\n",
    "    assert all(\"b\" in seed for seed in seeds)\n",
    "    assert all(isinstance(seed[\"a\"], str) for seed in seeds)\n",
    "    assert all(isinstance(seed[\"b\"], str) for seed in seeds)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def summarize_seeds(seeds):\n",
    "    # Create the system message\n",
    "    system_message = SUMMARIZE_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please summarize the following perspective pairs into a single perspective pair:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seed_dict, dict), \"Failed for: \" + str(seed_dict)\n",
    "    assert \"a\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert \"b\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"a\"], str), \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"b\"], str), \"Failed for: \" + str(seed_dict)\n",
    "\n",
    "    return seed_dict\n",
    "\n",
    "\n",
    "def get_names(seeds):\n",
    "    # Create the system message\n",
    "    system_message = LABEL_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please provide a name for each of perspective sets a and b, given the following pairs of perspectives:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seed_dict, dict), \"Failed for: \" + str(seed_dict)\n",
    "    assert \"a\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert \"b\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"a\"], str), \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"b\"], str), \"Failed for: \" + str(seed_dict)\n",
    "\n",
    "    return seed_dict\n",
    "\n",
    "\n",
    "# def get_three_sentences(a, b):\n",
    "def get_k_sentences(a, b, k):\n",
    "    # Create the system message\n",
    "    system_message = SENTENCE_SYSTEM_MESSAGE\n",
    "    # print(a, b, k)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"\"\n",
    "    prompt += \"a: \" + a + \"\\n\"\n",
    "    prompt += \"b: \" + b + \"\\n\"\n",
    "    prompt += \"Please generate \" + str(k) + \" pairs of sentences.\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SENTENCE_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Get the sentences\n",
    "    sentence_dict = json.loads(resp.choices[0].message.content)\n",
    "    a_sentences = list(sentence_dict[\"a\"].values())\n",
    "    b_sentences = list(sentence_dict[\"b\"].values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(a_sentences, list)\n",
    "    assert isinstance(b_sentences, list)\n",
    "    assert len(a_sentences) == k\n",
    "    assert len(b_sentences) == k\n",
    "    assert all(isinstance(sentence, str) for sentence in a_sentences)\n",
    "    assert all(isinstance(sentence, str) for sentence in b_sentences)\n",
    "\n",
    "    # return a_sentences, b_sentences\n",
    "    return {\n",
    "        \"a\": a_sentences,\n",
    "        \"b\": b_sentences,\n",
    "    }\n",
    "\n",
    "\n",
    "# Define a function to generate the dataset in parallel\n",
    "def generate_dataset(topic, n, k):\n",
    "    # Create seeds\n",
    "    seeds = get_seeds(topic, n)\n",
    "    # print(json.dumps(seeds, indent=2))\n",
    "\n",
    "    # Print seed pairs\n",
    "    print(\"Seed pairs:\")\n",
    "    for i, seed in enumerate(seeds):\n",
    "        # print(f\"{i+1}: a: {seed['a']}, b: {seed['b']}\")\n",
    "        print(\"Pair \" + str(i + 1) + \":\")\n",
    "        print(\"  a: \" + seed[\"a\"])\n",
    "        print(\"  b: \" + seed[\"b\"])\n",
    "\n",
    "    # Distill seeds\n",
    "    distilled = distil_seeds(seeds)\n",
    "\n",
    "    # Print distilled seeds\n",
    "    print(\"Distilled seeds:\")\n",
    "    for i, seed in enumerate(distilled):\n",
    "        print(\"Pair \" + str(i + 1) + \":\")\n",
    "        print(\"  a: \" + seed[\"a\"])\n",
    "        print(\"  b: \" + seed[\"b\"])\n",
    "\n",
    "    # Summarize seeds\n",
    "    summarized = summarize_seeds(seeds)\n",
    "\n",
    "    # Print summarized seeds\n",
    "    print(\"Summarized seeds:\")\n",
    "    print(f\"  a: {summarized['a']}\")\n",
    "    print(f\"  b: {summarized['b']}\")\n",
    "    \n",
    "    # Get names\n",
    "    names = get_names(seeds)\n",
    "    \n",
    "    # Print names\n",
    "    print(\"Names:\")\n",
    "    print(f\"  a: {names['a']}\")\n",
    "    print(f\"  b: {names['b']}\")\n",
    "\n",
    "    # Create a function to generate dataset for a single seed\n",
    "    def generate_dataset_for_seed(seed):\n",
    "        a = seed[\"a\"]\n",
    "        b = seed[\"b\"]\n",
    "        a_first = get_k_sentences(a, b, k)\n",
    "        b_first = get_k_sentences(b, a, k)\n",
    "\n",
    "        # Swap a and b in b_first\n",
    "        b_first = {\n",
    "            \"a\": b_first[\"b\"],\n",
    "            \"b\": b_first[\"a\"],\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            # \"seed\": seed,\n",
    "            # \"a_first\": get_k_sentences(seed[\"a\"], seed[\"b\"], k),\n",
    "            # \"b_first\": get_k_sentences(seed[\"b\"], seed[\"a\"], k),\n",
    "            \"seed\": seed,\n",
    "            \"a_first\": a_first,\n",
    "            \"b_first\": b_first,\n",
    "        }\n",
    "\n",
    "    # Generate the dataset in parallel using joblib\n",
    "    dataset = Parallel(n_jobs=THREADS, backend=\"threading\")(\n",
    "        delayed(generate_dataset_for_seed)(seed) for seed in tqdm(seeds)\n",
    "    )\n",
    "\n",
    "    if not dataset:\n",
    "        raise ValueError(\"No dataset generated\")\n",
    "\n",
    "    return seeds, distilled, summarized, names, dataset\n",
    "\n",
    "\n",
    "# Test\n",
    "# generate_dataset(\"Climate change\", 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1771d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:21:48.343873Z",
     "iopub.status.busy": "2024-02-16T03:21:48.343703Z",
     "iopub.status.idle": "2024-02-16T03:23:57.218798Z",
     "shell.execute_reply": "2024-02-16T03:23:57.218418Z"
    },
    "papermill": {
     "duration": 128.882948,
     "end_time": "2024-02-16T03:23:57.220216",
     "exception": false,
     "start_time": "2024-02-16T03:21:48.337268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed pairs:\n",
      "Pair 1:\n",
      "  a: Domestic violence is a serious crime that should be addressed with strict legal measures.\n",
      "  b: Domestic issues should be resolved privately without involving legal authorities.\n",
      "Pair 2:\n",
      "  a: Victims of domestic violence should be encouraged to speak out and seek help immediately.\n",
      "  b: Discussing domestic violence publicly can bring shame to the family and should be avoided.\n",
      "Pair 3:\n",
      "  a: Men can also be victims of domestic violence and deserve the same support and resources as women.\n",
      "  b: Domestic violence against men is not as severe or widespread as it is against women.\n",
      "Pair 4:\n",
      "  a: Preventive education and awareness campaigns are essential to stop domestic violence.\n",
      "  b: Focusing on prevention does not help the current victims of domestic violence.\n",
      "Pair 5:\n",
      "  a: The government should provide more shelters and resources for victims of domestic violence.\n",
      "  b: Too much government intervention in domestic issues can lead to unnecessary interference in personal lives.\n",
      "Pair 6:\n",
      "  a: Children witnessing domestic violence are at risk of long-term psychological effects.\n",
      "  b: Children are resilient and can easily overcome the impact of witnessing domestic violence.\n",
      "Pair 7:\n",
      "  a: Alcohol and drugs are often a cause of domestic violence.\n",
      "  b: Blaming substances like alcohol and drugs oversimplifies the problem and ignores the underlying issues.\n",
      "Pair 8:\n",
      "  a: Law enforcement officers should receive special training to handle domestic violence incidents effectively.\n",
      "  b: Special training for law enforcement is unnecessary; domestic violence cases should be treated like any other crime.\n",
      "Pair 9:\n",
      "  a: Social media platforms should do more to help victims of domestic violence find support and resources.\n",
      "  b: Social media is not the appropriate place to handle sensitive issues like domestic violence.\n",
      "Pair 10:\n",
      "  a: Economic independence is crucial for victims to leave abusive relationships.\n",
      "  b: Focusing on economic independence oversimplifies the complex reasons why victims stay in abusive relationships.\n",
      "Pair 11:\n",
      "  a: The stigma surrounding domestic violence must be eradicated for victims to feel safe coming forward.\n",
      "  b: The so-called stigma of domestic violence is exaggerated and not a significant barrier to seeking help.\n",
      "Pair 12:\n",
      "  a: Domestic violence is a pattern of behavior used to establish power and control over another person.\n",
      "  b: Some argue that what is labeled as domestic violence is often just an emotional response to stressful situations.\n",
      "Pair 13:\n",
      "  a: The media should portray domestic violence more responsibly to avoid perpetuating stereotypes.\n",
      "  b: Media portrayal of domestic violence is necessary for public awareness and should not be censored.\n",
      "Pair 14:\n",
      "  a: Bystanders have a responsibility to intervene or report if they suspect domestic violence.\n",
      "  b: Intervention by bystanders can escalate the situation and make it worse for the victim.\n",
      "Pair 15:\n",
      "  a: Domestic violence laws should include protections for pets, as they can also be victims or used as a control mechanism.\n",
      "  b: Extending domestic violence protections to pets dilutes the focus on human victims.\n",
      "Pair 16:\n",
      "  a: Cultural norms and values play a significant role in the prevalence and acceptance of domestic violence.\n",
      "  b: Highlighting cultural factors as a cause of domestic violence can unfairly stigmatize certain communities.\n",
      "Pair 17:\n",
      "  a: Mandatory reporting by healthcare professionals can help identify and support victims of domestic violence.\n",
      "  b: Mandatory reporting can deter victims from seeking medical help for fear of forced legal intervention.\n",
      "Pair 18:\n",
      "  a: Public figures and celebrities should use their platform to speak against domestic violence.\n",
      "  b: Public figures speaking out can oversimplify the issue and overshadow the voices of actual victims.\n",
      "Pair 19:\n",
      "  a: Gender stereotypes contribute to the perpetuation of domestic violence.\n",
      "  b: Focusing too much on gender stereotypes can ignore the individual circumstances of each case of domestic violence.\n",
      "Pair 20:\n",
      "  a: Restorative justice programs can be an effective way to address domestic violence.\n",
      "  b: Restorative justice programs may not provide enough protection for victims and can potentially endanger them further.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled seeds:\n",
      "Pair 1:\n",
      "  a: Domestic violence is a serious crime that should be addressed with strict legal measures.\n",
      "  b: Domestic issues should be resolved privately without involving legal authorities.\n",
      "Pair 2:\n",
      "  a: Men can also be victims of domestic violence and deserve the same support and resources as women.\n",
      "  b: Domestic violence against men is not as severe or widespread as it is against women.\n",
      "Pair 3:\n",
      "  a: Children witnessing domestic violence are at risk of long-term psychological effects.\n",
      "  b: Children are resilient and can easily overcome the impact of witnessing domestic violence.\n",
      "Pair 4:\n",
      "  a: The government should provide more shelters and resources for victims of domestic violence.\n",
      "  b: Too much government intervention in domestic issues can lead to unnecessary interference in personal lives.\n",
      "Pair 5:\n",
      "  a: Cultural norms and values play a significant role in the prevalence and acceptance of domestic violence.\n",
      "  b: Highlighting cultural factors as a cause of domestic violence can unfairly stigmatize certain communities.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized seeds:\n",
      "  a: Domestic violence is a complex issue that requires public awareness, legal intervention, and support for victims, including men, children, and pets, and should not be minimized or handled privately.\n",
      "  b: There are concerns that public discussion and certain interventions in domestic violence can bring shame, escalate situations, or detract from individual support needs, advocating for privacy and caution in addressing these matters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names:\n",
      "  a: Support\n",
      "  b: Opposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                               | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 5456.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seeds, distilled, summarized, names, dataset = generate_dataset(TOPIC, N, K)\n",
    "\n",
    "# # Get the raw list of sentences (shuffled) for the dataset\n",
    "# a_sentences = []\n",
    "# b_sentences = []\n",
    "# for data in dataset:\n",
    "#     for key in [\"a_first\", \"b_first\"]:\n",
    "#         a_data = data[key][\"a\"]\n",
    "#         b_data = data[key][\"b\"]\n",
    "#         if key == \"b_first\":\n",
    "#             a_data, b_data = b_data, a_data\n",
    "\n",
    "#         for sentence in a_data:\n",
    "#             a_sentences.append(sentence)\n",
    "#         for sentence in b_data:\n",
    "#             b_sentences.append(sentence)\n",
    "\n",
    "# # Shuffle both lists\n",
    "# import random\n",
    "\n",
    "# random.shuffle(a_sentences)\n",
    "# random.shuffle(b_sentences)\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "\n",
    "# os.makedirs(\"corpora\", exist_ok=True)\n",
    "folder = f\"corpora/{TOPIC.lower().replace(' ', '_')}\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# outname = f\"{folder}/{SEED_MODEL}_{SENTENCE_MODEL}_{N}_{K}.json\"\n",
    "\n",
    "outname = f\"{folder}/{N}_{K}.json\"\n",
    "\n",
    "# Save data\n",
    "with open(outname, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"topic\": TOPIC,\n",
    "            \"N\": N,\n",
    "            \"K\": K,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"seed_model\": SEED_MODEL,\n",
    "            \"sentence_model\": SENTENCE_MODEL,\n",
    "            \"seeds\": seeds,\n",
    "            \"distilled\": distilled,\n",
    "            \"summarized\": summarized,\n",
    "            \"names\": names,\n",
    "            \"dataset\": dataset,\n",
    "            # \"a_sentences\": a_sentences,\n",
    "            # \"b_sentences\": b_sentences,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774afcdb",
   "metadata": {
    "papermill": {
     "duration": 0.006115,
     "end_time": "2024-02-16T03:23:57.232776",
     "exception": false,
     "start_time": "2024-02-16T03:23:57.226661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 130.281572,
   "end_time": "2024-02-16T03:23:57.453726",
   "environment_variables": {},
   "exception": null,
   "input_path": "generate_synthetic_generic.ipynb",
   "output_path": "corpora/Domestic violence.ipynb",
   "parameters": {
    "K": 10,
    "N": 20,
    "TEMPERATURE": 0.5,
    "THREADS": 20,
    "TOPIC": "Domestic violence"
   },
   "start_time": "2024-02-16T03:21:47.172154",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}