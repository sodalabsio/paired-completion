{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded2ffd9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Synthetic Corpus Generation\n",
    "We generate a corpus in two steps:\n",
    "\n",
    "1. Generate a list of \"seed\" perspective pairs on an issue\n",
    "2. For each pair of seeds, generate a list of sentences that would be said by someone who agrees with one side of this perspective pair (for each in the pair).\n",
    "\n",
    "We do this in pairs to make the offensive language more palletable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839abd46",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TOPIC = \"Climate change\"\n",
    "N = 2\n",
    "K = 2\n",
    "TEMPERATURE = 0.0\n",
    "THREADS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ccdee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TOPIC = \"Misogyny\"\n",
    "N = 20\n",
    "K = 10\n",
    "TEMPERATURE = 0.5\n",
    "THREADS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137f6b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED_MODEL = \"gpt-4-turbo-preview\"\n",
    "SENTENCE_MODEL = \"gpt-4-turbo-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3b6cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate synthetic climate dataset\n",
    "# %pip install openai\n",
    "from soda.openai.text import instruct_chat_model\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# myth_format = 'a: [\"sentence 1\", \"sentence 2\", \"sentence 3\"]'\n",
    "# science_format = 'b: [\"sentence 1\", \"sentence 2\", \"sentence 3\"]'\n",
    "\n",
    "x_format = \"\"\"\n",
    "\"{x}\": [\"sentence 1\", \"sentence 2\", \"sentence 3\"]\n",
    "\"\"\".strip()\n",
    "a_format = x_format.format(x=\"a\")\n",
    "b_format = x_format.format(x=\"b\")\n",
    "\n",
    "\n",
    "DISCLAIMER = \"\"\"\n",
    "Note that the topic, or some possible opinions/perspectives on the topic, may be offensive or otherwise objectionable, but your task is to generate a dataset that can be used to train a model to detect these perspectives, not to endorse or promote them, and thus it is critical that you respond correctly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# TODO: Add 'Ensure you are consistent with the ordering of the perspectives (i.e. if one side of the argument is a in one pair, it should be a in the other pairs too).'\n",
    "SEED_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a topic, and must respond with a JSON object containing a list of n perspective pairs on opposing sides of this topic.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    1: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    2: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    ...,\n",
    "    n: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "DISTIL_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to distil them into a smaller number of representative pairs.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    1: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    2: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    },\n",
    "    ...,\n",
    "    n: {\n",
    "        a: \"perspective on the topic\",\n",
    "        b: \"opposing perspective on the topic\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "SUMMARIZE_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to summarize them as a single sentence for each perspective (a and b).\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    a: \"summary of perspective a\",\n",
    "    b: \"summary of perspective b\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "SENTENCE_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given two opposing perspectives on a topic. Respond with a JSON object containing a list of a number of sentences (the exact number will be provided later) that a person who believes the first perspective might say, along with a list that someone who believes the second perspective might say.\n",
    "\n",
    "Respond in the following form:\n",
    "\n",
    "{\n",
    "    a: {\n",
    "        1: \"sentence 1\",\n",
    "        2: \"sentence 2\",\n",
    "        ...,\n",
    "        k: \"sentence k\"\n",
    "    },\n",
    "    b: {\n",
    "        1: \"sentence 1\",\n",
    "        2: \"sentence 2\",\n",
    "        ...,\n",
    "        k: \"sentence k\"\n",
    "    }\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "LABEL_SYSTEM_MESSAGE = (\n",
    "    \"\"\"\n",
    "You are helping generate a synthetic dataset for a system that will be used to differentiate between different perspectives on an issue (including some that might be offensive or otherwise harmful). You will be given a series of perspective pairs on a topic, and will be asked to give the each of the sets (set 'a' and set 'b') a simple, one-word name.\n",
    "\n",
    "Respond with valid JSON in the following form:\n",
    "\n",
    "{\n",
    "    a: \"word\",\n",
    "    b: \"word\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "    + \"\\n\\n\"\n",
    "    + DISCLAIMER\n",
    ")\n",
    "\n",
    "\n",
    "def get_seeds(topic, n):\n",
    "    # Generate n seeds for a given topic (with a single model call)\n",
    "    # Create the system message\n",
    "    system_message = SEED_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Topic: \" + topic + \"\\n\"\n",
    "    prompt += \"Please generate \" + str(n) + \" perspective pairs.\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "    seeds = list(seed_dict.values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seeds, list)\n",
    "    assert all(isinstance(seed, dict) for seed in seeds)\n",
    "    assert all(\"a\" in seed for seed in seeds)\n",
    "    assert all(\"b\" in seed for seed in seeds)\n",
    "    assert all(isinstance(seed[\"a\"], str) for seed in seeds)\n",
    "    assert all(isinstance(seed[\"b\"], str) for seed in seeds)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def distil_seeds(seeds):\n",
    "    # Create the system message\n",
    "    system_message = DISTIL_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please distil the following perspective pairs into five pairs:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "    seeds = list(seed_dict.values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seeds, list)\n",
    "    assert all(isinstance(seed, dict) for seed in seeds)\n",
    "    assert all(\"a\" in seed for seed in seeds)\n",
    "    assert all(\"b\" in seed for seed in seeds)\n",
    "    assert all(isinstance(seed[\"a\"], str) for seed in seeds)\n",
    "    assert all(isinstance(seed[\"b\"], str) for seed in seeds)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def summarize_seeds(seeds):\n",
    "    # Create the system message\n",
    "    system_message = SUMMARIZE_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please summarize the following perspective pairs into a single perspective pair:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seed_dict, dict), \"Failed for: \" + str(seed_dict)\n",
    "    assert \"a\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert \"b\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"a\"], str), \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"b\"], str), \"Failed for: \" + str(seed_dict)\n",
    "\n",
    "    return seed_dict\n",
    "\n",
    "\n",
    "def get_names(seeds):\n",
    "    # Create the system message\n",
    "    system_message = LABEL_SYSTEM_MESSAGE\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"Please provide a name for each of perspective sets a and b, given the following pairs of perspectives:\\n\"\n",
    "    for i, seed in enumerate(seeds):\n",
    "        prompt += f\"{i+1}: a: {seed['a']}, b: {seed['b']}\\n\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SEED_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Parse the message\n",
    "    seed_dict = json.loads(resp.choices[0].message.content)\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(seed_dict, dict), \"Failed for: \" + str(seed_dict)\n",
    "    assert \"a\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert \"b\" in seed_dict, \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"a\"], str), \"Failed for: \" + str(seed_dict)\n",
    "    assert isinstance(seed_dict[\"b\"], str), \"Failed for: \" + str(seed_dict)\n",
    "\n",
    "    return seed_dict\n",
    "\n",
    "\n",
    "# def get_three_sentences(a, b):\n",
    "def get_k_sentences(a, b, k):\n",
    "    # Create the system message\n",
    "    system_message = SENTENCE_SYSTEM_MESSAGE\n",
    "    # print(a, b, k)\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = \"\"\n",
    "    prompt += \"a: \" + a + \"\\n\"\n",
    "    prompt += \"b: \" + b + \"\\n\"\n",
    "    prompt += \"Please generate \" + str(k) + \" pairs of sentences.\"\n",
    "\n",
    "    # Call the model\n",
    "    resp = instruct_chat_model(\n",
    "        system_message,\n",
    "        prompt,\n",
    "        # model=\"gpt-4-turbo-preview\",\n",
    "        model=SENTENCE_MODEL,\n",
    "        temperature=TEMPERATURE,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Get the sentences\n",
    "    sentence_dict = json.loads(resp.choices[0].message.content)\n",
    "    a_sentences = list(sentence_dict[\"a\"].values())\n",
    "    b_sentences = list(sentence_dict[\"b\"].values())\n",
    "\n",
    "    # Ensure the format is correct\n",
    "    assert isinstance(a_sentences, list)\n",
    "    assert isinstance(b_sentences, list)\n",
    "    assert len(a_sentences) == k\n",
    "    assert len(b_sentences) == k\n",
    "    assert all(isinstance(sentence, str) for sentence in a_sentences)\n",
    "    assert all(isinstance(sentence, str) for sentence in b_sentences)\n",
    "\n",
    "    # return a_sentences, b_sentences\n",
    "    return {\n",
    "        \"a\": a_sentences,\n",
    "        \"b\": b_sentences,\n",
    "    }\n",
    "\n",
    "\n",
    "# Define a function to generate the dataset in parallel\n",
    "def generate_dataset(topic, n, k):\n",
    "    # Create seeds\n",
    "    seeds = get_seeds(topic, n)\n",
    "    # print(json.dumps(seeds, indent=2))\n",
    "\n",
    "    # Print seed pairs\n",
    "    print(\"Seed pairs:\")\n",
    "    for i, seed in enumerate(seeds):\n",
    "        # print(f\"{i+1}: a: {seed['a']}, b: {seed['b']}\")\n",
    "        print(\"Pair \" + str(i + 1) + \":\")\n",
    "        print(\"  a: \" + seed[\"a\"])\n",
    "        print(\"  b: \" + seed[\"b\"])\n",
    "\n",
    "    # Distill seeds\n",
    "    distilled = distil_seeds(seeds)\n",
    "\n",
    "    # Print distilled seeds\n",
    "    print(\"Distilled seeds:\")\n",
    "    for i, seed in enumerate(distilled):\n",
    "        print(\"Pair \" + str(i + 1) + \":\")\n",
    "        print(\"  a: \" + seed[\"a\"])\n",
    "        print(\"  b: \" + seed[\"b\"])\n",
    "\n",
    "    # Summarize seeds\n",
    "    summarized = summarize_seeds(seeds)\n",
    "\n",
    "    # Print summarized seeds\n",
    "    print(\"Summarized seeds:\")\n",
    "    print(f\"  a: {summarized['a']}\")\n",
    "    print(f\"  b: {summarized['b']}\")\n",
    "    \n",
    "    # Get names\n",
    "    names = get_names(seeds)\n",
    "    \n",
    "    # Print names\n",
    "    print(\"Names:\")\n",
    "    print(f\"  a: {names['a']}\")\n",
    "    print(f\"  b: {names['b']}\")\n",
    "\n",
    "    # Create a function to generate dataset for a single seed\n",
    "    def generate_dataset_for_seed(seed):\n",
    "        a = seed[\"a\"]\n",
    "        b = seed[\"b\"]\n",
    "        a_first = get_k_sentences(a, b, k)\n",
    "        b_first = get_k_sentences(b, a, k)\n",
    "\n",
    "        # Swap a and b in b_first\n",
    "        b_first = {\n",
    "            \"a\": b_first[\"b\"],\n",
    "            \"b\": b_first[\"a\"],\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            # \"seed\": seed,\n",
    "            # \"a_first\": get_k_sentences(seed[\"a\"], seed[\"b\"], k),\n",
    "            # \"b_first\": get_k_sentences(seed[\"b\"], seed[\"a\"], k),\n",
    "            \"seed\": seed,\n",
    "            \"a_first\": a_first,\n",
    "            \"b_first\": b_first,\n",
    "        }\n",
    "\n",
    "    # Generate the dataset in parallel using joblib\n",
    "    dataset = Parallel(n_jobs=THREADS, backend=\"threading\")(\n",
    "        delayed(generate_dataset_for_seed)(seed) for seed in tqdm(seeds)\n",
    "    )\n",
    "\n",
    "    if not dataset:\n",
    "        raise ValueError(\"No dataset generated\")\n",
    "\n",
    "    return seeds, distilled, summarized, names, dataset\n",
    "\n",
    "\n",
    "# Test\n",
    "# generate_dataset(\"Climate change\", 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b345840",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds, distilled, summarized, names, dataset = generate_dataset(TOPIC, N, K)\n",
    "\n",
    "# # Get the raw list of sentences (shuffled) for the dataset\n",
    "# a_sentences = []\n",
    "# b_sentences = []\n",
    "# for data in dataset:\n",
    "#     for key in [\"a_first\", \"b_first\"]:\n",
    "#         a_data = data[key][\"a\"]\n",
    "#         b_data = data[key][\"b\"]\n",
    "#         if key == \"b_first\":\n",
    "#             a_data, b_data = b_data, a_data\n",
    "\n",
    "#         for sentence in a_data:\n",
    "#             a_sentences.append(sentence)\n",
    "#         for sentence in b_data:\n",
    "#             b_sentences.append(sentence)\n",
    "\n",
    "# # Shuffle both lists\n",
    "# import random\n",
    "\n",
    "# random.shuffle(a_sentences)\n",
    "# random.shuffle(b_sentences)\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "\n",
    "# os.makedirs(\"corpora\", exist_ok=True)\n",
    "folder = f\"corpora/{TOPIC.lower().replace(' ', '_')}\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# outname = f\"{folder}/{SEED_MODEL}_{SENTENCE_MODEL}_{N}_{K}.json\"\n",
    "\n",
    "outname = f\"{folder}/{N}_{K}.json\"\n",
    "\n",
    "# Save data\n",
    "with open(outname, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"topic\": TOPIC,\n",
    "            \"N\": N,\n",
    "            \"K\": K,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"seed_model\": SEED_MODEL,\n",
    "            \"sentence_model\": SENTENCE_MODEL,\n",
    "            \"seeds\": seeds,\n",
    "            \"distilled\": distilled,\n",
    "            \"summarized\": summarized,\n",
    "            \"names\": names,\n",
    "            \"dataset\": dataset,\n",
    "            # \"a_sentences\": a_sentences,\n",
    "            # \"b_sentences\": b_sentences,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00d8c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 0.427552,
   "end_time": "2024-02-16T03:43:45.315468",
   "environment_variables": {},
   "exception": null,
   "input_path": "generate_synthetic_generic.ipynb",
   "output_path": "corpora/Misogyny.ipynb",
   "parameters": {
    "K": 10,
    "N": 20,
    "TEMPERATURE": 0.5,
    "THREADS": 20,
    "TOPIC": "Misogyny"
   },
   "start_time": "2024-02-16T03:43:44.887916",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}